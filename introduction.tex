\section{Introduction}
\label{introduction}

Implantable medical devices like pacemakers are designed to improve certain undesired physiological conditions with very little human interventions. 
Their ability of autonomously affect the physiological conditions of the patients makes the medical devices safety-critical, and sufficient evidence on the safety and efficacy of the devices should be provided before the devices can be implanted in the patients. 
As more functions added to the devices, the complexity of the software component of the device is increasing dramatically, leading to increasing number of potential safety violations due to software bugs. 
\todo{give recall statistics}
In what follows, we use the word `device' to refer both to the hardware and the software of the device.

There are two categories of device bugs: 
first, the device may fail to conform to its \emph{specification}, i.e. the prescription of how it should react to certain inputs.  
Secondly, even if it conforms to its specification, the device may fail to improve the health of the patient as promised. 
The improved state of health is captured in the \emph{physiological requirements}; e.g., for a pacemaker, the heart rate should always be below a certain threshold. 
%In what follows, the word `requirement' always refers to such physiological requirements.
Note that requirements are about \emph{the closed-loop system}: they prescribe the behavior of both device and environment (e.g. both pacemaker and heart).

Bugs in the first category (non-conformance to specification) are detected via extensive open-loop testing where a set of input sequences is fed to the device, and its output is observed to see if it matches the expected output.
Bugs in the second category (violation of physiological requirements), on the other hand, require the availability of the closed-loop system: e.g., the heart and the pacemaker. 
In the medical device industry, clinical trials amount to a closed-loop test of the device and its software. 
In a clinical trial, the actual device is implanted in a human subject and its operation tested over a certain duration.
Unfortunately, clinical trials can only cover a very limited range of physiological conditions due to their extremely high cost and long duration. 
\todo{give dollar amount and duration}
Moreover, clinical trials are often conducted at the last design stage. Fixing bugs at this stage is also very costly.

On the other hand, using a virtual model of the device's environment, we can conduct \emph{model-based clinical trials}: i.e., the device (or a model thereof) is connected to a virtual model of the environment and this virtual closed loop is verified.
Depending on the formalism used to model the environment (and device) and the language used to express the requirements, this allows the usage of formal methods to perform the verification.
Environment modeling introduces new challenges and issues that do not arise when modeling the device alone, and this paper aims at addressing these issues in the context of pacemaker verification.
The proposed method is also generalizable to other contexts where closed-loop formal verification is desired.
In the rest of this paper, we speak therefore of pacemaker as the Device Under Verification (DUV) and of the heart as being the environment, but it is understood that the discussion carries more broadly, with possible domain-specific adjustments.

The first challenge in closed-loop verification of pacemakers is that the human heart displays a large number of different conditions, henceforth referred to as `physiological conditions'.
\footnote{The medical term is `arrhythmias'.} 
E.g., one heart may display \emph{atrial fibrillation} where the upper chambers of the heart (the atria) produce an exceedingly fast beat that prevents proper blood pumping.
Another heart may display Premature Ventricular Contraction (PVC) where a location in the ventricles produces electrical impulses at erratic time instants.
Each such condition will require its own formal model, and some models may display more than one condition.
This initial set of models will necessarily be incomplete: the number of conditions is too large, and some of the conditions are too ill-understood for modeling.
Thus, unlike system modeling where one typically starts from one ground truth model to be verified, our starting point is an \emph{incomplete set of models}.
In this paper, we build such a set of formal heart models using a network of timed automata in Section ???.
Model checking for timed automata is decidable [???].

Next, in typical formal verification practice, when the state space of a model $M$ is too large, \emph{predicate abstraction} is used to reduce the size of the state space while still preserving all the behavior of the original model. 
This reduction in size may allow model checking where it wasn't possible before. 
Because the abstract model $M'$ also introduces new behavior that didn't exist in the ground truth $M$, this new behavior is rejected as \emph{spurious} if it is encountered, and the abstraction is refined.
This is the familiar CEGAR procedure[???].
However when modeling the environment, we use abstraction differently. 
Because we start from an \emph{incomplete} set of models, we would like our abstraction procedures to introduce new \emph{physiologically meaningful} behavior which might actually be produced by heart models not in the initial set.
These then correspond to heart conditions not taken explicitly into account. 
This motivates the introduction of domain-specific abstraction rules $R$ in Section ???: like predicate abstraction, they produce models that over-approximate the behavior of the model they are applied to (i.e., $\beh(R(M)) \supset \beh(M)$).
However, the new behavior they introduce might not be spurious. 
We demonstrate such a case in Section ???.
If model checking returns a counter-example on $R(M)$, the physician can decide whether this is actually physiologically plausible behavior and therefore the pacemaker needs to be debugged, or this is indeed spurious and should be thrown out (and the abstraction refined).

Note also that predicate abstraction deals with only one model. 
In the proposed framework, the abstraction rules can apply to several models $M_1,\ldots,M_n$ at a time, and can merge them together such that $\cup_{i=1}^n R(\beh(M_i)) \subset \beh(M)$.
Moreover, because we start from a set of initial models, and use a set of abstraction rules, we actually produce an \emph{abstraction tree} rather than an abstraction chain.
We demonstrate the construction and use of such a tree for the formal verification of pacemakers in Section ???

\subsection{Technical preliminaries}
In this section we briefly review the notions of abstraction and over-approximation of system.
Let $M$ be a system model and $S$ be its state space (in Section ??? we give a specific formalism in which our systems are modeled).
A \emph{trace} $\straj$ of $M$ is an infinite sequence of states produced by $M$: $\straj \in S^\omega$.The \emph{behavior}
\subsection{The Model Checking Problem}
Model-based design has been proposed to speed up system software design and provide safety promises in physiological requirements. ]
For a model $M$ with state space $S$, we define a behavior of the model as an execution trace $\delta\in S^*$. The reachable behavior space of the model $M$ is denoted as $\mathbb{B}(M)\subset S^*$. A property $\varphi$ defines a region in the behavior space within which the property is satisfied, which can be denoted as $\mathbb{B}(\varphi)$. A model checking problem is to use mathematical tool to explore the whole reachable behaviors of a model $M$ against a property $\varphi$ such that $\mathbb{B}(M)\subseteq \mathbb{B}(\varphi)$. We denote it as $M\models\varphi$. Execution traces $\delta_v\in\mathbb{B}(M)/(\mathbb{B}(M)\cap\mathbb{B}(\varphi))$ will be returned by the model checker as property violations so that the designer can analyze and address the problem. 

In closed-loop model checking, the closed-loop system $M_E||M_P$ consists of the system under check $M_P$, and environment conditions modeled as $M_E$. In the case of medical devices, the devices are designed to improve certain physiological conditions. In general, a closed-loop requirement $\varphi_C$ is in the form of $\varphi_E\Rightarrow \varphi_P$, in which $\varphi_E$ is the open-loop physiological condition that the device encounters, and $\varphi_P$ is the closed-loop physiological condition that the device should achieve. Then we have:
 \begin{equation}\label{req_def}
M_E\models\varphi_E, M_E||M_P\models \varphi_P\Rightarrow M_E||M_P\models\varphi_C
\end{equation}

\subsection{Model Abstraction with Over-approximation}
The behavior space of the actual system is too large for model checker to exhaustively explore. A model of the system which covers all behaviors of the system can be developed which can not only reduce complexity, but also having the suitable formalism for the model checker. An abstraction function $h$ abstracting model $M$ to $M'$ is a non-surjective function from state space $S$ to the new abstract state space $S'$ such that: 
$$\forall s\in S, \exists s'\in S' \text{ s.t. } h(s)=s'$$
This definition can be extended to behaviors $\delta\in \mathbb{B}(M)$, such that:
$$\forall \delta\in \mathbb{B}(M),\exists \delta'\in\mathbb{B}(M')\text{ s.t. } h(\delta)=h(\delta')$$
From the definition, we know that the abstract model $M'$ covers all behaviors of $M$, which is referred to as \emph{over-approximation}. We represent the over-approximation relationship as $M\triangleleft_h M'$, and the relationship between reachable behavior spaces as $h(\mathbb{B}(M))\subseteq\mathbb{B}(M')$. Then we have:
$$h(\mathbb{B}(M))\subseteq \mathbb{B}(M'),\mathbb{B}(M')\subseteq h(\mathbb{B}(\varphi))\Rightarrow h(\mathbb{B}(M))\subseteq h(\mathbb{B}(\varphi))\Rightarrow M\models\varphi$$
\todo[inline]{The behavior space in which $\varphi$ is defined need to be clarified.}
In general the state space of $S'$ is smaller than $S$ while preserving the property, thus preferable during model checking. 

Over-approximation can also be used to cover the behaviors of multiple models. A model $M'$ is an over-approximation of model $M_1$ and $M_2$ if 
$$\forall \delta\in \mathbb{B}(M_1)\cup\mathbb{B}(M_2),\exists \delta'\in\mathbb{B}(M')\text{ s.t. } h(\delta)=h(\delta')$$
We denote it as $\{M_1,M_2\}\triangleleft_h M'$, such that $h(\mathbb{B}(M_1)\cup\mathbb{B}(M_2))\subseteq\mathbb{B}(M')$.

\subsection{Ambiguities Caused by Over-approximation}
\subsubsection{Validity Ambiguities: }
Since $h$ is non-surjective, there exists behaviors in $M'$ that do not exists in the original model $M$:
$$\exists\delta'\in\mathbb{B}(M')\text{ s.t. }h^{-1}(\delta')\not\subset\mathbb{B}(M)$$
These invalid behaviors may contribute to false-negatives during model checking.
\subsubsection{Context Ambiguities: }
For models over-approximated to cover the behaviors of multiple models, distinct behaviors from different models can be indistinguishable in the abstract model. For $\{M_1,M_2\}\triangleleft_h M'$, we may have :
$$ \delta_1\in\mathbb{B}(M_1),\delta_2\in \mathbb{B}(M_2)\text{ s.t. }h(\delta_1)=h(\delta_2)=\delta',\delta'\in \mathbb{B}(M')$$
It is not a problem if $M'\models\varphi$, however if $\delta'\not\models\varphi$ is returned as a counter-example, it loses the context in which the property is violated and is hard to interpret the result. A small example is shown in \figref{ambiguity} to illustrate the potential ambiguities due to over-approximation. 

\begin{figure}[!t]
		\centering
		\includegraphics[width=0.8\textwidth]{figs/distinction.png}
		%\vspace{-5pt}
		\caption{\small Two models such that $\{Sys1,Sys2\}\triangleleft_h M$. An over-approximation function $h_a$ is applied to $M$ to obtain $M'$. By model checking the abstract model $M'$ against property $\varphi$ we have $M'\not\models\varphi$ and $\delta'$ is returned as counter-example. However, $\delta'$ corresponds to 3 different behaviors in the original behavior space}
		  %\vspace{-15pt}
		\label{fig:ambiguity}
\end{figure}

\subsection{System Modeling vs. Environment Modeling}
During closed-loop model checking, there are different focuses on the system model and the model of its environment, thus modeling them require different strategy.
\subsubsection{Over-approximation: }In closed-loop model checking, there is only one concrete system. However there can be countless number of environmental conditions which require different models to represent. While over-approximating the system model aim to reduce its state space and computational cost, over-approximating the environment models aim to cover the behaviors of multiple environmental conditions that are explicitly modeled, or implicitly included. Since it is impossible to exhaustively model all possible environment conditions, over-approximation is a good way to cover multiple environment condition without increasing computational cost. %\figref{distinction}

\subsubsection{Validity of a counter-example: }Behaviors introduced into the over-approximation of a system model are all \emph{spurious}, or invalid. For two models such that $M\triangleleft_h M'$, $\delta'$ is spurious if the following condition holds: 
$$\not\exists \delta\in\mathbb{B}(M) \text{ s.t. }h(\delta)=\delta'$$
However, for environment models such that $\{M_1,M_2,...M_n\}\triangleleft_h M'$, and an execution $\delta'\in\mathbb{B}(M')$, the following condition is not enough to prove $\delta'$ is spurious.
$$\forall i\not\exists \delta\in\mathbb{B}(M_i)\text{ s.t. }h(\delta)=\delta'$$
Since there may be a valid environment model $M_c\not\in\{M_1,M_2,...M_n\}$ and $\mathbb{B}(M_c)\subset\mathbb{B}(M')$ and $\delta'\in\mathbb{B}(M_c)$. It is thus up to the domain experts to determine the validity of the counter-example.
%\begin{figure}[!b]
%		\centering
%		\includegraphics[width=0.6\textwidth]{figs/env_sys.png}
%		%\vspace{-5pt}
%		\caption{\small }
%		  %\vspace{-15pt}
%		\label{fig:distinction}
%\end{figure}

\subsection{Counter-Example-Guided Abstraction and Refinement (CEGAR)}
In \cite{CEGAR} the authors proposed a framework to over-approximate the system using proposition abstraction. Upon property violation the abstract counter-example is checked for its validity on the system. If the counter-example is spurious the model is then refined to eliminate the spurious counter-example. This process is then resumed on the refined model until either a valid counter-example returns or no counter-examples are returned.

From the above procedure we can see that CEGAR framework works on system modeling. However, CEGAR cannot be applied for environment modeling for the following reasons. First, the proposition abstraction can not over-approximate multiple models into one abstract model. 
%Proposition abstraction only abstract the domain of the substates and the dimensions of the state space is unchanged. For environment models with different substates, more aggressive abstraction functions are needed to over-approximate
With multiple environment models the validity of counter-examples cannot be determined by concretizing them on the set of environment models, as discussed in the last section. If over-approximation is used for environment modeling, there needs to be a more suitable framework to balance the abstraction and refinement of the environment models.

\subsection{Abstraction-tree-based Model Abstraction for Environment Modeling}
In this paper we propose framework for environment modeling in closed-loop model checking of medical device software. An incomplete set of physiological models are first developed to represent different physiological conditions. 

A set of physiological abstraction rules are then developed based on physiological knowledge, which ensure the physiological relevance of the behaviors introduced into the abstract models. 

Then the rules are applied in certain order onto the set of physiological models, resulting an abstraction tree $G=(V,E)$. Each leaf in the tree is a physiological model and the edges are applications of an abstraction rule. The abstraction tree can then be used as environment models for closed-loop model checking.

The closed-loop requirement $\varphi_c:(\varphi_E\Rightarrow\varphi_P)$ has constraints on the environment in $\varphi_E$. During the abstraction steps, certain sub-states or transitions of the environment models may be removed or merged. If the variables mentioned in $\varphi_E$, which is denoted as $Var(\varphi_E)$, is not a subset of the variables of an environment model $M$, which is denoted as $Var(M)$, the model $M$ is not appropriate for the requirement $\varphi_c$. The first step for closed-loop model checking is to choose the most abstract environment model(s) from the tree which are appropriate for the requirement. These models will be used as the initial environment models $M_E$ during model checking. 

For a system model $M_S$ and a physiological requirement $\varphi_c$, closed-loop model checking is performed such that:
$$\forall M\in M_E, \text{ check } M||M_S\models\varphi_c$$
If the requirement is all satisfied, the system model $M_S$ satisfy $\varphi_c$ under environment condition covered by the models in $M_E$. Upon violation of the requirement, the model checker returns a counter-example $\delta_c\in M_c\in M_E$. However, counter-examples at the abstract level are difficult to interpret and there may exists ambiguities. To concretize the counter-example and enumerate possible physiological context, we explore the abstraction tree. Model checking is then performed such that:
$$\forall M\in Child(M_c), \text{ check } M||M_S\models\varphi_c$$  
The procedure recurs until 1) the leaves of the tree is reached, or 2) there is no violations in the child nodes. The counter-examples returned from the most refined models are then submitted to the physicians for analysis. 

%\todo[inline]{why give new names to familiar things? Especially since these names don't make sense at this point. E.g. you speak of validity ambiguity, but it is not at all clear what is being validated and why the equation expresses an `ambiguity'. This is basically a description of what happens when abstracting, which most formal people are familiar with, so merge with section \ref{MCproblem}}



%During the software development process, there are two key documents that track the safety and efficacy of the software component, namely the \textbf{Software Requirements} and \textbf{Software Specifications}. These two terms are sometimes used interchangeably, however, requirements and specifications provides different angle of system safety and require very different verification techniques.
%
%A requirement states the objective of the system in design in terms of environmental conditions. For example, a requirement of a self-driving car would be: \emph{The car should not hit a pedestrian.} A specification is how the system developers propose to satisfy the requirements. For example, the specification corresponding to the requirement of a self-driving car would be: \emph{If an object is detected in front of the car and the distance to the object is less than $d$, the car should brake.} As we can see, a specification may not satisfy the corresponding requirement, thus two steps are required to guarantee the safety of the system software. The first is the conformance between the system software and the software specification. The second one is whether the software specifications can satisfy all the software requirements.
%
%Currently in most system design, the conformance between the software specifications and the system software are verified using extensive \textbf{open-loop} testing. The test cases are extracted from the system software using static analysis based on certain coverage criteria. The conformance between the specifications and the requirements are maintained by traceability documents, which is insufficient for safety guarantee.
% \begin{figure}[!t]
% 		\centering
% 		\includegraphics[width=0.8\textwidth]{figs/SysVSEnv.png}
% 		%\vspace{-5pt}
% 		\caption{\small Modeling in terms of behavior coverage. As model becomes more abstract, the coverage increases while the boundary becomes more simple. (a) System modeling in which there is only one concrete system; (b) Environment modeling in which abstraction can be used to generalize different conditions}
% 		  %\vspace{-15pt}
% 		\label{fig:sys}
% \end{figure}





\input{contributions}


%\paragraph{Notation}. For a positive integer $n$, $[n] = \{1,2,\ldots,n\}$.

%\input{formulation}
%\input{example}