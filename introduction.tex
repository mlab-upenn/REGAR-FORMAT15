\section{Introduction}
\label{introduction}

Implantable medical devices like pacemakers are designed to improve physiological conditions with very little human intervention. 
Their ability of autonomously affecting the physiological state of the patient makes the medical devices safety-critical, and sufficient evidence for their safety and efficacy should be provided before the devices can be implanted in the patients. 
As more functionality is added to the devices
\footnote{In what follows, we use the word `device' to refer both to the software of the device.}
, the complexity of the software component of the device is increasing dramatically, leading to a large number of potential safety violations due to software bugs \cite{recall_stats}.


There are two categories of device bugs: 
1) the device may fail to conform to its \emph{specifications}, i.e. the prescription of how it should react to certain inputs.  
2) the device may fail to improve the conditions of the patient as promised, even if it conforms to its specifications. 
The desired physiological conditions that the closed-loop system should achieve are captured in the \emph{physiological requirements}; e.g., for a pacemaker, the heart rate should always be maintained above a certain threshold. 
%In what follows, the word `requirement' always refers to such physiological requirements.
%Note that requirements are about \emph{the closed-loop system}: they prescribe the behavior of both device and environment (e.g. both pacemaker and heart).

Bugs in the first category (non-conformance to specification) can be detected via systematic and extensive open-loop testing in which a set of input sequences is fed to the device, and its output is compared with the expected output.
Bugs in the second category (violation of physiological requirements), on the other hand, require the availability of the closed-loop system: e.g., the pacemaker and the heart as its environment. 
In the medical device industry, closed-loop verification of the physiological requirements are mostly performed in terms of clinical trials, in which the actual devices are implanted in human subjects over an extended duration.
Unfortunately, due to the extremely high cost, the amount and variety of human subjects during the clinical trials are limited, which affects their capability to find bugs. 
%\todo{give dollar amount}
%Moreover, clinical trials are often conducted at the last design stage. Fixing bugs at this stage is very costly.

%On the other hand, using a virtual model of the device's environment, we can conduct \emph{model-based clinical trials}: i.e., the device (or a model thereof) is connected to a virtual model of the environment and this virtual closed loop is verified.
Closed-loop model checking enables closed-loop evaluation of physiological requirements at earlier design stage, which requires formal model(s) of the physiological environment. 
%Depending on the formalism used to model the environment (and device) and the language used to express the requirements, this allows the usage of formal methods to perform the verification.
%Formal environment modeling introduces new challenges that do not arise when modeling the device alone, and this paper aims at addressing these issues in the context of pacemaker verification.
%In the rest of this paper, we speak therefore of pacemaker as the Device Under Verification (DUV) and of the heart as being the environment, but it is understood that the discussion carries more broadly, with possible domain-specific adjustments.
In closed-loop model checking, there is only one concrete system. However there can be countless number of environmental conditions which require different models to represent. A set of initial models of the environment can be constructed but the set is inherently incomplete due to the large number of environment conditions and their combinations. As the result, performing model checking using every models in the set cannot ensure full coverage on environment conditions. 

Over-approximation has been proposed in system modeling to reduce the state space while covering all the behaviors of the system. Over-approximation can be extended to environment modeling. By carefully designing over-approximation rules, the abstract model not only covers explicitly modeled environment conditions, but also covers behaviors and conditions not modeled in the set of initial models. The abstract model can be then used for closed-loop model checking. If a requirement is satisfied, the system under verification satisfy the requirement under environment conditions covered by the abstract model. 

However, if the requirement is unsatisfied, the model checker returns a counter-example. The counter-example is not necessarily a bug since it may be a behavior that does not belong to any environment conditions, but was introduced into the abstract model during over-approximation. In system modeling the validity of the counter-example can be easily checked on the one and only concrete system. However in environment modeling, due to the possibly valid behaviors introduced in the abstract model, the validity of the counter-example cannot be determined even if it is not valid in all the models in the initial model set. Thus the validity of a counter-example can only be determined by domain experts, which is made challenging due to the possible lose of environment context during the over-approximation. One abstract counter-example may also correspond to multiple valid conditions, which causes ambiguity. A rigorous framework is thus needed to balance the coverage and environment context of the environment models.

Counter-Example Guided Abstraction and Refinement (CEGAR) \cite{CEGAR} has been proposed to over-approximate the system using predicate abstraction. Upon property violation the abstract counter-example is checked for its validity on the actual system. If the counter-example is \emph{spurious} the model is then refined to eliminate the spurious counter-example. This process is then continued on the refined model until either a valid counter-example returns or no counter-examples are returned. CEGAR works well during system modeling, however, it cannot be applied to environment modeling for two reasons: 1) predicate abstraction does not guarantee the validity of behaviors introduced into the model. In fact, for system modeling, all additional behaviors introduced into the abstract model are spurious. 2) the validity of a counter-example cannot be checked automatically as in system modeling.

In \cite{sttt13} we developed a set of heart models with different abstraction levels for closed-loop model checking of implantable pacemaker. The models were constructed and abstracted manually using domain knowledge. Models at different abstraction levels have a timed simulation relationship which are also proved manually. Upon property violation in an abstract model, the validity of the counter-example is checked manually and the appropriate refinement is also chosen manually to eliminate spurious counter-examples. This framework requires extensive domain expertise in each step which is not easy to use in real applications.

\subsection{Contributions}
In this paper we propose a semi-automated framework for environment modeling in closed-loop model checking of medical device software. 
We use implantable pacemaker and heart modeling as an example. 
An expandable set of heart models are first developed to represent different physiological conditions. 
A set of domain-specific abstraction rules are then developed based on physiological knowledge, which ensure the physiological relevance of the behaviors introduced into the abstract models. Then the rules are applied onto the initial set of heart models to obtain an abstraction tree, which will be used for closed-loop model checking of the pacemaker. 
Domain knowledge is only needed when constructing the initial model set and defining the abstraction rules. 
Once the abstraction tree is constructed, no domain knowledge is needed. 
We propose an algorithm for performing model-checking of the closed loop using the abstraction tree.
The algorithm returns the most concrete counter-example (if it exists) to be examined by the domain expert, along with the heart models that produce it.
The proposed method can potentially generalized to other domains in which the system operates in a large variety of environmental conditions.
%
